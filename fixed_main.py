# -*- coding: utf-8 -*-
import os
import re
import json
import aiohttp
import logging
import asyncio
from datetime import datetime
from bs4 import BeautifulSoup
from telethon import TelegramClient, events
from functools import lru_cache
from PIL import Image
from io import BytesIO
import brotli  # Add Brotli import

# ====== CONFIG ======
CONFIG_FILE = 'bot_config.json'

def load_config():
    default_config = {
        'api_id': None,
        'api_hash': None
    }
    
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, 'r') as f:
            return json.load(f)
    return default_config.copy()

def save_config(config):
    with open(CONFIG_FILE, 'w') as f:
        json.dump(config, f, indent=4)

def setup_config():
    config = load_config()
    
    print("=== Pinterest Bot Configuration ===")
    print("Press Enter to keep current value (shown in brackets)")
    
    # Get API ID
    current_api_id = config.get('api_id', 'Not set')
    api_id = input(f"Enter Telegram API ID [{current_api_id}]: ").strip()
    if api_id:
        config['api_id'] = int(api_id)
    elif config['api_id'] is None:
        raise ValueError("API ID is required for first setup")

    # Get API Hash
    current_api_hash = config.get('api_hash', 'Not set')
    api_hash = input(f"Enter Telegram API Hash [{current_api_hash}]: ").strip()
    if api_hash:
        config['api_hash'] = api_hash
    elif config['api_hash'] is None:
        raise ValueError("API Hash is required for first setup")

    # Save the configuration
    save_config(config)
    print("Configuration saved successfully!")
    return config

def get_config():
    try:
        config = load_config()
        if None in config.values():
            config = setup_config()
        return config
    except Exception as e:
        print(f"Error loading configuration: {e}")
        return setup_config()

# Load configuration
config = get_config()
api_id = config['api_id']
api_hash = config['api_hash']

# ====== LOGGING SETUP ======
def log(msg, end='\n'):
    print(f'[üåÄ] {msg}', end=end)

# ====== TELETHON SETUP ======
client = TelegramClient('session', api_id, api_hash)
logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')

# ====== SESSION SETUP ======
session = None

async def get_session():
    global session
    if session is None:
        try:
            # Try to configure session with AsyncResolver
            connector = aiohttp.TCPConnector(
                resolver=aiohttp.AsyncResolver(),
                ssl=False,
                use_dns_cache=True
            )
            session = aiohttp.ClientSession(connector=connector)
        except Exception as e:
            log(f"‚ö†Ô∏è Kh√¥ng th·ªÉ s·ª≠ d·ª•ng AsyncResolver, d√πng c·∫•u h√¨nh m·∫∑c ƒë·ªãnh: {e}")
            # Fallback to default configuration
            session = aiohttp.ClientSession(
                connector=aiohttp.TCPConnector(ssl=False)
            )
    return session

# ====== DOWNLOAD FUNCTION ======
async def download_file(url, filename, max_retries=3):
    log(f'‚¨áÔ∏è ƒêang t·∫£i: {url}')
    retry_count = 0
    chunk_size = 4 * 1024 * 1024  # 4MB chunks for faster download
    
    while retry_count < max_retries:
        try:
            session = await get_session()
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': '*/*',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive'
            }
            async with session.get(url, headers=headers) as response:
                response.raise_for_status()
                total_size = int(response.headers.get('content-length', 0))
                
                if url.endswith('.jpg') or url.endswith('.png') or url.endswith('.jpeg') or url.endswith('.webp'):
                    log('üì• ƒêang t·∫£i d·ªØ li·ªáu ·∫£nh...')
                    data = await response.read()
                    img = Image.open(BytesIO(data))
                    
                    # Convert WEBP to JPEG if needed
                    if url.endswith('.webp'):
                        img = img.convert('RGB')
                    
                    width, height = img.size
                    log(f'üìè K√≠ch th∆∞·ªõc g·ªëc: {width}x{height}')
                    
                    # Calculate target size (4K or larger)
                    if max(width, height) < 3840:
                        scale = 3840 / max(width, height)
                        new_width = int(width * scale)
                        new_height = int(height * scale)
                        log(f'üîÑ N√¢ng c·∫•p ·∫£nh l√™n {new_width}x{new_height}')
                        img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                    
                    # Save with maximum quality
                    log('üíæ ƒêang l∆∞u ·∫£nh ch·∫•t l∆∞·ª£ng cao...')
                    img.save(filename, 'JPEG', quality=100, optimize=True, subsampling=0)
                    
                    log(f'‚ú® ƒê√£ l∆∞u ·∫£nh ch·∫•t l∆∞·ª£ng cao: {filename}')
                else:
                    # For videos and other files
                    log('üì• ƒêang t·∫£i video/file...')
                    downloaded = 0
                    with open(filename, 'wb') as f:
                        async for chunk in response.content.iter_chunked(chunk_size):
                            f.write(chunk)
                            downloaded += len(chunk)
                            if total_size:
                                progress = (downloaded / total_size) * 100
                                log(f'\rüì• T·∫£i xu·ªëng: {progress:.1f}% ({downloaded/1024/1024:.1f}/{total_size/1024/1024:.1f}MB)', end='')
                
                log(f'‚úÖ T·∫£i xu·ªëng ho√†n t·∫•t: {filename}')
                return True
            
        except Exception as e:
            retry_count += 1
            if retry_count < max_retries:
                wait_time = 2 ** retry_count  # Exponential backoff
                log(f'‚ö†Ô∏è L·ªói t·∫£i file (l·∫ßn {retry_count}): {e}. Th·ª≠ l·∫°i sau {wait_time}s...')
                await asyncio.sleep(wait_time)
            else:
                log(f'‚ùå L·ªói t·∫£i file sau {max_retries} l·∫ßn th·ª≠: {e}')
                # Clean up partial file if it exists
                if os.path.exists(filename):
                    os.remove(filename)
                return False

# ====== PINTEREST EXTRACTOR ======
@lru_cache(maxsize=100)
async def extract_pinterest_media(pin_url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': '*/*',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Cookie': '_auth=1'
    }
    session = await get_session()
    log(f'‚û° ƒêang x·ª≠ l√Ω link: {pin_url}')

    try:
        # Handle short links with retries
        if 'pin.it' in pin_url or '/i/' in pin_url:
            retry_count = 0
            max_retries = 3
            while retry_count < max_retries:
                try:
                    log(f'üîÑ ƒêang gi·∫£i quy·∫øt link ng·∫Øn (l·∫ßn th·ª≠ {retry_count + 1})...')
                    timeout = aiohttp.ClientTimeout(total=10)  # 10 seconds timeout
                    async with session.get(pin_url, headers=headers, allow_redirects=True, timeout=timeout) as response:
                        if response.status == 200:
                            # Get the final URL after redirects
                            final_url = str(response.url)
                            log(f'‚û° Link g·ªëc: {final_url}')
                            
                            # Try to find canonical URL from the page
                            content = await response.text()
                            soup = BeautifulSoup(content, "html.parser")
                            meta = soup.find("link", rel="canonical")
                            if meta and meta.get('href'):
                                final_url = meta['href']
                                log(f'‚û° Link ch√≠nh th·ª©c: {final_url}')
                            
                            # Update pin_url to the resolved URL if it's valid
                            if 'pinterest.com' in final_url:
                                pin_url = final_url
                                break
                            else:
                                log('‚ö†Ô∏è Link ƒë√≠ch kh√¥ng ph·∫£i Pinterest, th·ª≠ l·∫°i...')
                        else:
                            log(f'‚ö†Ô∏è L·ªói HTTP {response.status}, th·ª≠ l·∫°i...')
                    
                except asyncio.TimeoutError:
                    log('‚ö†Ô∏è H·∫øt th·ªùi gian ch·ªù, th·ª≠ l·∫°i...')
                except Exception as e:
                    log(f'‚ö†Ô∏è L·ªói khi gi·∫£i quy·∫øt link ng·∫Øn: {e}')
                
                retry_count += 1
                if retry_count < max_retries:
                    wait_time = 2 ** retry_count
                    log(f'‚åõ Ch·ªù {wait_time}s tr∆∞·ªõc khi th·ª≠ l·∫°i...')
                    await asyncio.sleep(wait_time)
                else:
                    log('‚ùå Kh√¥ng th·ªÉ gi·∫£i quy·∫øt link ng·∫Øn sau nhi·ªÅu l·∫ßn th·ª≠')

        async with session.get(pin_url, headers=headers) as response:
            if response.status != 200:
                return None, None
            content = await response.text()
            soup = BeautifulSoup(content, 'html.parser')

            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† video kh√¥ng
            is_video = False
            video_candidates = []
            
            # Ph∆∞∆°ng ph√°p 1: Ki·ªÉm tra meta tags
            for meta in soup.find_all('meta', property=['og:type', 'og:video:type']):
                if 'video' in meta.get('content', '').lower():
                    is_video = True
                    break

            # Ph∆∞∆°ng ph√°p 2: Ki·ªÉm tra th·∫ª video
            video_tag = soup.find("video")
            if video_tag:
                is_video = True
                log('üé• Ph√°t hi·ªán video qua th·∫ª video...')

            # Ph∆∞∆°ng ph√°p 3: Ki·ªÉm tra trong d·ªØ li·ªáu JSON
            for script in soup.find_all('script', type='text/javascript'):
                if 'videoList' in script.text or '"type":"video"' in script.text:
                    is_video = True
                    log('üé• Ph√°t hi·ªán video qua d·ªØ li·ªáu JSON...')
                    break

            if is_video:
                log('üé• X√°c nh·∫≠n ƒë√¢y l√† video Pinterest, ƒëang qu√©t t·∫•t c·∫£ ngu·ªìn...')
                
                # Thu th·∫≠p ngu·ªìn video t·ª´ th·∫ª video
                if video_tag:
                    if 'src' in video_tag.attrs:
                        video_candidates.append(video_tag['src'])
                    
                    for source in video_tag.find_all('source'):
                        if source.get('src'):
                            video_candidates.append(source['src'])
                
                # Thu th·∫≠p t·ª´ meta tags
                for meta in soup.find_all('meta', property=['og:video', 'og:video:url', 'og:video:secure_url']):
                    if meta.get('content'):
                        video_candidates.append(meta['content'])
                
                # Thu th·∫≠p t·ª´ script data
                for script in soup.find_all('script', type=['application/json', 'text/javascript']):
                    try:
                        # X·ª≠ l√Ω script d·∫°ng JSON
                        script_content = script.string or script.text
                        try:
                            data = json.loads(script_content)
                        except json.JSONDecodeError:
                            # N·∫øu kh√¥ng ph·∫£i JSON, d√πng vƒÉn b·∫£n g·ªëc
                            data = script_content

                        def find_video_urls(obj):
                            urls = []
                            if isinstance(obj, dict):
                                # T√¨m ki·∫øm c√°c tr∆∞·ªùng video c·ª• th·ªÉ c·ªßa Pinterest
                                video_fields = ['video_url', 'videoUrl', 'url', 'high_res_url']
                                for field in video_fields:
                                    if field in obj and isinstance(obj[field], str):
                                        if any(ext in obj[field].lower() for ext in ['.mp4', '.m3u8']):
                                            urls.append(obj[field])
                                
                                # T√¨m trong c√°c ƒë·ªëi t∆∞·ª£ng video
                                if 'videos' in obj:
                                    if isinstance(obj['videos'], dict):
                                        for video_data in obj['videos'].values():
                                            if isinstance(video_data, dict) and 'url' in video_data:
                                                urls.append(video_data['url'])
                                    elif isinstance(obj['videos'], list):
                                        for video_data in obj['videos']:
                                            if isinstance(video_data, dict) and 'url' in video_data:
                                                urls.append(video_data['url'])
                                
                                # ƒê·ªá quy t√¨m trong c√°c ƒë·ªëi t∆∞·ª£ng con
                                for v in obj.values():
                                    if isinstance(v, (dict, list)):
                                        urls.extend(find_video_urls(v))
                            elif isinstance(obj, list):
                                for item in obj:
                                    urls.extend(find_video_urls(item))
                            elif isinstance(obj, str):
                                # T√¨m URL video trong chu·ªói vƒÉn b·∫£n
                                video_patterns = [
                                    r'https?://[^"\']+?\.mp4[^"\']*',
                                    r'https?://[^"\']+?/video/[^"\']+',
                                    r'https?://v\.pinimg\.com[^"\']+',
                                ]
                                for pattern in video_patterns:
                                    urls.extend(re.findall(pattern, obj))
                            return urls

                        found_urls = find_video_urls(data)
                        if found_urls:
                            log(f'üé• T√¨m th·∫•y {len(found_urls)} URL video trong script')
                            video_candidates.extend(found_urls)

                    except Exception as e:
                        log(f'‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω script: {e}')
                        continue

                # T√¨m phi√™n b·∫£n ch·∫•t l∆∞·ª£ng cao nh·∫•t
                best_video = {'url': None, 'size': 0}
                for video_url in set(video_candidates):  # Lo·∫°i b·ªè tr√πng l·∫∑p
                    base_url = video_url.split('/hls/')[0] if '/hls/' in video_url else video_url.rsplit('/', 1)[0]
                    quality_variants = [
                        ('/originals/', '.mp4'),
                        ('/h265_4k/', '.mp4'),
                        ('/hevc_4k/', '.mp4'),
                        ('/4k/', '.mp4'),
                        ('/2160p/', '.mp4'),
                        ('/h265_1440p/', '.mp4'),
                        ('/1440p/', '.mp4'),
                        ('/1080p/', '.mp4')
                    ]
                    
                    for path, ext in quality_variants:
                        try:
                            test_url = f"{base_url}{path}video{ext}"
                            async with session.head(test_url, headers=headers) as resp:
                                if resp.status == 200:
                                    size = int(resp.headers.get('content-length', 0))
                                    if size > best_video['size']:
                                        best_video = {'url': test_url, 'size': size}
                                        log(f'üìà T√¨m th·∫•y phi√™n b·∫£n t·ªët h∆°n: {test_url} ({size/1024/1024:.1f}MB)')
                        except:
                            continue
                
                if best_video['url']:
                    return 'video', best_video['url']

            # Ch·ªâ t√¨m ·∫£nh n·∫øu kh√¥ng ph·∫£i l√† video
            if not is_video:
                img_sources = []
                
                # Ki·ªÉm tra c√°c meta tags kh√°c nhau
                meta_tags = [
                    ("meta", {"property": "og:image"}),
                    ("meta", {"name": "twitter:image"}),
                    ("meta", {"name": "pinterest:image"}),
                    ("meta", {"property": "og:image:url"}),
                    ("link", {"rel": "image_src"})
                ]
                
                log("üîç T√¨m ki·∫øm ·∫£nh trong meta tags...")
                for tag, attrs in meta_tags:
                    elem = soup.find(tag, attrs)
                    if elem:
                        url = elem.get('content') or elem.get('href')
                        if url:
                            if 'pinimg.com' in url:
                                url = re.sub(r'/\d+x/', '/originals/', url)
                                log(f'üîÑ N√¢ng c·∫•p ·∫£nh l√™n ch·∫•t l∆∞·ª£ng cao nh·∫•t: {url}')
                            img_sources.append(url)
                            log(f'‚úÖ T√¨m th·∫•y ·∫£nh t·ª´ {tag}: {url}')

                log("üîç T√¨m ki·∫øm ·∫£nh trong th·∫ª img...")
                for img in soup.find_all("img"):
                    src = img.get('src', '')
                    if not src:
                        continue
                    
                    if 'pinimg.com' in src:
                        src = re.sub(r'/\d+x/', '/originals/', src)
                    
                    if any(x in src.lower() for x in ['original', 'fullsize', '1200x', '736x']):
                        img_sources.append(src)
                        log(f'‚úÖ T√¨m th·∫•y ·∫£nh ch·∫•t l∆∞·ª£ng cao: {src}')
                    elif 'src' in img.attrs:
                        img_sources.append(src)
                        log(f'‚úÖ T√¨m th·∫•y ·∫£nh: {src}')

                # Ch·ªçn ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i cao nh·∫•t
                log(f"üîç ƒê√°nh gi√° {len(img_sources)} ·∫£nh t√¨m th·∫•y...")
                best_image = None
                max_resolution = 0

                for img_url in img_sources:
                    try:
                        if 'originals' in img_url:
                            log(f'üéØ T√¨m th·∫•y ·∫£nh g·ªëc: {img_url}')
                            return 'image', img_url

                        if 'pinimg.com' in img_url:
                            original_url = re.sub(r'/\d+x/', '/originals/', img_url)
                            log(f'üîÑ Th·ª≠ truy c·∫≠p ·∫£nh g·ªëc: {original_url}')
                            try:
                                async with session.head(original_url, headers=headers) as response:
                                    if response.status == 200:
                                        log(f'‚úÖ ·∫¢nh g·ªëc kh·∫£ d·ª•ng!')
                                        return 'image', original_url
                            except:
                                log('‚ö†Ô∏è Kh√¥ng th·ªÉ truy c·∫≠p ·∫£nh g·ªëc, d√πng ·∫£nh thay th·∫ø')

                        res_match = re.search(r'(\d+)x(\d+)', img_url)
                        if res_match:
                            resolution = int(res_match.group(1)) * int(res_match.group(2))
                            log(f'üìè ·∫¢nh {img_url} c√≥ ƒë·ªô ph√¢n gi·∫£i: {res_match.group(1)}x{res_match.group(2)}')
                            if resolution > max_resolution:
                                max_resolution = resolution
                                best_image = img_url
                                log(f'üìà C·∫≠p nh·∫≠t ·∫£nh ch·∫•t l∆∞·ª£ng cao nh·∫•t: {img_url}')
                    except Exception as e:
                        log(f'‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω ·∫£nh {img_url}: {e}')
                        continue

                if best_image:
                    log(f'‚úÖ Ch·ªçn ·∫£nh t·ªët nh·∫•t: {best_image}')
                    return 'image', best_image
                
                if img_sources:
                    log(f'‚ö†Ô∏è Kh√¥ng t√¨m ƒë∆∞·ª£c ·∫£nh ch·∫•t l∆∞·ª£ng cao, d√πng ·∫£nh ƒë·∫ßu ti√™n: {img_sources[0]}')
                    return 'image', img_sources[0]

    except Exception as e:
        log(f'L·ªói khi tr√≠ch xu·∫•t media: {e}')
    
    return None, None

# ====== COMMAND HANDLERS ======
@client.on(events.NewMessage(pattern='/start'))
async def start_handler(event):
    chat = await event.get_chat()
    log(f'Bot started in chat: {chat.id} ({"Group" if hasattr(chat, "title") else "Private"})')
    await event.reply(
        "üëã Xin ch√†o! T√¥i l√† bot t·∫£i ·∫£nh/video t·ª´ Pinterest.\n"
        "Ch·ªâ c·∫ßn g·ª≠i link Pinterest, t√¥i s·∫Ω t·ª± ƒë·ªông t·∫£i v√† g·ª≠i l·∫°i media cho b·∫°n!\n"
        "üîó H·ªó tr·ª£ c·∫£ link pinterest.com v√† pin.it"
    )

# ====== HANDLE ANY MESSAGE WITH PINTEREST LINK ======
@client.on(events.NewMessage)
async def handler(event):
    try:
        # Ignore commands
        if event.raw_text.startswith('/'):
            return

        text = event.raw_text
        if 'pinterest.com' not in text and 'pin.it' not in text:
            return

        chat = await event.get_chat()
        chat_info = f'Chat ID: {chat.id} ({"Group" if hasattr(chat, "title") else "Private"})'
        
        # T√¨m t·∫•t c·∫£ c√°c link Pinterest trong tin nh·∫Øn
        links = re.findall(r'(https?://(?:www\.)?(?:pinterest\.com/(?:[^\s]+|i/[^\s/]+)|pin\.it/[^\s]+))', text)
        if not links:
            return

        log(f'Ph√°t hi·ªán {len(links)} link Pinterest trong {chat_info}')
        await event.reply("üîç ƒêang x·ª≠ l√Ω link Pinterest c·ªßa b·∫°n...")

        processed = []
        for link in links:
            try:
                log(f'X·ª≠ l√Ω link: {link} trong {chat_info}')
                file_type, url = await extract_pinterest_media(link)

                if not url:
                    continue

                filename = datetime.now().strftime("%d%m%H%M%S") + f"_{len(processed)}"
                if file_type == 'video':
                    filename += '.mp4'
                elif file_type == 'image':
                    filename += '.jpg'

                if await download_file(url, filename):
                    processed.append(filename)
                    log(f'‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng: {url}')
                else:
                    log(f'‚ùå Kh√¥ng th·ªÉ t·∫£i: {url}')
            except Exception as e:
                log(f'‚ùå L·ªói khi x·ª≠ l√Ω {link}: {e}')

        if processed:
            try:
                # G·ª≠i t·ª´ng file m·ªôt ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô
                for filename in processed:
                    try:
                        file_size = os.path.getsize(filename)
                        log(f'üì§ ƒêang g·ª≠i file {filename} ({file_size/1024/1024:.1f}MB)...')
                        
                        # G·ª≠i file
                        await event.reply(file=filename)
                        log(f'‚úÖ ƒê√£ g·ª≠i th√†nh c√¥ng: {filename}')
                        
                        # X√≥a file ngay sau khi g·ª≠i
                        os.remove(filename)
                        log(f'üßπ ƒê√£ xo√° file: {filename}')
                    except Exception as e:
                        log(f'‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω file {filename}: {e}')
                        # ƒê·∫£m b·∫£o x√≥a file ngay c·∫£ khi g·∫∑p l·ªói
                        if os.path.exists(filename):
                            os.remove(filename)
                
                log(f'‚ú® ƒê√£ x·ª≠ l√Ω xong {len(processed)} file trong {chat_info}')
            except Exception as e:
                log(f'‚ùå L·ªói khi g·ª≠i files: {e}')
                # D·ªçn d·∫πp t·∫•t c·∫£ file c√≤n s√≥t l·∫°i
                for filename in processed:
                    if os.path.exists(filename):
                        try:
                            os.remove(filename)
                            log(f'üßπ ƒê√£ xo√° file th·ª´a: {filename}')
                        except:
                            pass
        else:
            await event.reply("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh ho·∫∑c video h·ª£p l·ªá.")
            log(f'‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y media h·ª£p l·ªá trong {chat_info}')

    except Exception as e:
        await event.reply(f"‚ùå ƒê√£ x·∫£y ra l·ªói: {e}")
        log(f'‚ùå L·ªói: {e}')

# ====== START BOT ======
async def shutdown(signal_=None):
    """Cleanup function to gracefully shut down the bot"""
    if signal_:
        log(f"\nüì¢ Nh·∫≠n t√≠n hi·ªáu: {signal_.name}")
    log("üîÑ ƒêang d·ª´ng bot...")
    
    # Close the aiohttp session
    if session:
        log("üîí ƒê√≥ng phi√™n HTTP...")
        await session.close()
    
    # Disconnect the Telegram client
    if client and client.is_connected():
        log("üîå Ng·∫Øt k·∫øt n·ªëi Telegram...")
        await client.disconnect()
    
    log("‚úÖ ƒê√£ d·ªçn d·∫πp xong!")
    log("üëã T·∫°m bi·ªát!")

async def main():
    try:
        # Set up signal handlers for graceful shutdown
        for sig in (signal.SIGINT, signal.SIGTERM):
            try:
                loop = asyncio.get_event_loop()
                loop.add_signal_handler(sig, lambda s=sig: asyncio.create_task(shutdown(s)))
            except NotImplementedError:
                # Windows doesn't support signal handlers
                pass
        
        log("ü§ñ Bot ƒëang kh·ªüi ƒë·ªông...")
        
        # Ki·ªÉm tra c·∫•u h√¨nh
        if not api_id or not api_hash:
            log("‚ùå Thi·∫øu th√¥ng tin c·∫•u h√¨nh API")
            log("‚ÑπÔ∏è H√£y ch·∫°y l·∫°i bot v√† nh·∫≠p API ID v√† API Hash")
            return
            
        log("üîÑ K·∫øt n·ªëi ƒë·∫øn Telegram...")
        await client.start()
        
        me = await client.get_me()
        log(f"‚úÖ Bot ƒë√£ s·∫µn s√†ng! (@{me.username})")
        log("üìù S·ª≠ d·ª•ng /start trong chat ƒë·ªÉ b·∫Øt ƒë·∫ßu")
        log("‚åõ ƒêang ch·ªù tin nh·∫Øn...")
        log("üí° Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng bot...")
        
        await client.run_until_disconnected()
    except ValueError as ve:
        log(f"‚ùå L·ªói c·∫•u h√¨nh: {ve}")
        log("‚ÑπÔ∏è H√£y xo√° file bot_config.json v√† ch·∫°y l·∫°i bot")
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        log(f"‚ùå L·ªói kh·ªüi ƒë·ªông bot: {e}")
        log(f"üìã Chi ti·∫øt l·ªói:\n{error_details}")
    finally:
        await shutdown()

# Run the bot
if __name__ == '__main__':
    try:
        # Import signal here to avoid issues on non-Unix platforms
        import signal
        
        # Ki·ªÉm tra file c·∫•u h√¨nh
        if not os.path.exists(CONFIG_FILE):
            log("‚öôÔ∏è Ch∆∞a c√≥ file c·∫•u h√¨nh, b·∫Øt ƒë·∫ßu thi·∫øt l·∫≠p...")
        
        asyncio.run(main())
    except KeyboardInterrupt:
        pass  # Handled by signal handlers
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        log(f"‚ùå L·ªói kh√¥ng mong mu·ªën: {e}")
        log(f"üìã Chi ti·∫øt l·ªói:\n{error_details}")